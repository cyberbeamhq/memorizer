# Memorizer - Intelligent Memory Management Library

[![License](https://img.shields.io/badge/license-MIT-blue.svg)](./LICENSE)
[![Python](https://img.shields.io/badge/python-3.8%2B-blue)](https://www.python.org/)

**A focused Python library for adding intelligent memory capabilities to AI applications.**

Memorizer provides memory storage, retrieval, lifecycle management, and external provider integrations without the complexity of application infrastructure.

## ğŸ¯ Core Focus

**Pure Memory Management** - No web servers, no containers, no infrastructure complexity. Just intelligent memory for your AI applications.

## âœ¨ Key Features

- **ğŸ§  Intelligent Memory Lifecycle**: Three-tier aging system (very_new â†’ mid_term â†’ long_term)
- **ğŸ” Hybrid Search**: Combines keyword and vector search for optimal retrieval
- **ğŸ¤– LLM Integration**: Works with OpenAI, Anthropic, Groq, and custom providers
- **ğŸ—„ï¸ External Providers**: Easy integration with Supabase, Railway, Neon, Pinecone, Weaviate
- **ğŸ›¡ï¸ PII Protection**: Built-in personally identifiable information filtering
- **âš¡ Simple API**: Get started in 3 lines of code

## ğŸš€ Quick Start

### Installation

```bash
pip install memorizer

# Optional: Install external provider dependencies
pip install pinecone-client weaviate-client supabase
```

### Basic Usage

```python
import memorizer

# Create a memory manager
memory = memorizer.create_memory()

# Store memories
user_id = "user123"
memory_id = memory.store_memory(user_id, "I love playing guitar")

# Search memories
results = memory.search_memories(user_id, "music hobbies")
print(f"Found {len(results.memories)} relevant memories")
```

### With External Providers

```python
import memorizer

# Use Supabase for storage and Pinecone for vectors
memory = memorizer.create_memory_manager(
    storage_provider="supabase",
    vector_store="pinecone",
    llm_provider="openai",
    supabase_url="https://your-project.supabase.co",
    supabase_password="your-password",
    pinecone_api_key="your-api-key"
)

# Same API
memory.store_memory("user123", "Working on a React project")
results = memory.search_memories("user123", "frontend development")
```

## ğŸ—ï¸ Architecture

### Memory Lifecycle

```
Input Memory
     â†“
[very_new] â†’ [mid_term] â†’ [long_term]
   7 days      30 days      365 days
     â†“           â†“            â†“
  Raw text â†’ Summarized â†’ Compressed
```

### Core Components

```
memorizer/
â”œâ”€â”€ memory/           # Memory manager and lifecycle
â”œâ”€â”€ core/            # Interfaces and configuration
â”œâ”€â”€ builtins/        # Storage, retrievers, summarizers
â”œâ”€â”€ storage/         # Database and external providers
â”œâ”€â”€ retrieval/       # Hybrid search algorithms
â”œâ”€â”€ security/        # PII detection and filtering
â””â”€â”€ integrations/    # LLM and agent integrations
```

## ğŸ“– Supported Providers

### Database Providers
- **Memory**: In-memory storage (development)
- **Supabase**: PostgreSQL with real-time features
- **Railway**: Simple PostgreSQL hosting
- **Neon**: Serverless PostgreSQL
- **PostgreSQL**: Direct PostgreSQL connection

### Vector Stores
- **Memory**: In-memory vectors (development)
- **SQLite**: Local vector storage
- **Pinecone**: Managed vector database
- **Weaviate**: Open-source vector search
- **Chroma**: Embedding database

### LLM Providers
- **OpenAI**: GPT models for summarization
- **Anthropic**: Claude models
- **Groq**: Fast inference
- **Mock**: For testing/development

## ğŸ”§ External Provider Setup

### Supabase Configuration

```python
import memorizer

memory = memorizer.create_memory_manager(
    storage_provider="supabase",
    supabase_url="https://your-project.supabase.co",
    supabase_password="your-database-password"
)
```

**Required Environment Variables:**
```bash
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_DB_PASSWORD=your_database_password
```

### Pinecone Configuration

```python
import memorizer

memory = memorizer.create_memory_manager(
    vector_store="pinecone",
    pinecone_api_key="your-api-key",
    pinecone_environment="us-west1-gcp"
)
```

**Required Environment Variables:**
```bash
PINECONE_API_KEY=your_api_key
PINECONE_ENVIRONMENT=us-west1-gcp
```

### Complete External Setup

```python
import memorizer

# Production setup with Supabase + Pinecone + OpenAI
memory = memorizer.create_memory_manager(
    storage_provider="supabase",
    vector_store="pinecone",
    llm_provider="openai",
    supabase_url="https://your-project.supabase.co",
    supabase_password="your-password",
    pinecone_api_key="your-pinecone-key",
    openai_api_key="your-openai-key"
)
```

## ğŸ§ª Examples

### Basic Memory Operations

```python
import memorizer

memory = memorizer.create_memory()
user_id = "demo_user"

# Store different types of memories
memories = [
    "I prefer morning workouts at 6 AM",
    "My favorite cuisine is Italian food",
    "Working on a Python ML project",
    "Planning a trip to Japan next year"
]

for content in memories:
    memory.store_memory(user_id, content)

# Search with different queries
queries = ["exercise habits", "food preferences", "programming work"]

for query in queries:
    results = memory.search_memories(user_id, query, limit=2)
    print(f"'{query}' found {len(results.memories)} memories")
```

### Integration with LangChain

```python
import memorizer
from langchain.memory import ConversationBufferMemory

# Create memory manager
memory_manager = memorizer.create_memory_manager(
    storage_provider="supabase",
    llm_provider="openai"
)

# Custom LangChain memory class
class MemorizerMemory(ConversationBufferMemory):
    def __init__(self, user_id: str, **kwargs):
        super().__init__(**kwargs)
        self.user_id = user_id
        self.memory_manager = memory_manager

    def save_context(self, inputs: dict, outputs: dict):
        # Save to both LangChain and Memorizer
        super().save_context(inputs, outputs)

        # Store in Memorizer for long-term memory
        conversation = f"User: {inputs.get('input', '')}\nAI: {outputs.get('output', '')}"
        self.memory_manager.store_memory(self.user_id, conversation)
```

### Custom AI Application

```python
import memorizer

class AIAssistant:
    def __init__(self, user_id: str):
        self.user_id = user_id
        self.memory = memorizer.create_memory_manager(
            storage_provider="supabase",
            vector_store="pinecone"
        )

    def process_message(self, message: str) -> str:
        # Retrieve relevant context
        context = self.memory.search_memories(
            self.user_id,
            message,
            limit=5
        )

        # Generate response (your LLM logic here)
        response = self.generate_response(message, context)

        # Store the interaction
        interaction = f"User: {message}\nAssistant: {response}"
        self.memory.store_memory(self.user_id, interaction)

        return response
```

## ğŸ“ Project Structure

```
memorizer/
â”œâ”€â”€ src/memorizer/          # Main library code
â”œâ”€â”€ examples/               # Example scripts and tutorials
â”œâ”€â”€ tests/                  # Test suite
â”œâ”€â”€ docs/                   # Documentation
â”œâ”€â”€ archive/                # Archived/legacy components
â”œâ”€â”€ README.md              # This file
â”œâ”€â”€ requirements.txt       # Core dependencies
â”œâ”€â”€ .env.example          # Environment configuration template
â”œâ”€â”€ memorizer.yaml.example # Advanced configuration template
â””â”€â”€ setup.py              # Package setup
```

## ğŸ¯ Perfect For

- ğŸ¤– **AI Chatbots** with persistent memory
- ğŸ” **RAG Applications** with intelligent context
- ğŸ“ **AI Writing Assistants** that remember user preferences
- ğŸ® **AI Game NPCs** with evolving personalities
- ğŸ“Š **Analytics Tools** that learn from interactions

## ğŸ†š Why Memorizer?

### vs. Building Your Own
- âœ… Proven memory lifecycle algorithms
- âœ… Battle-tested external provider integrations
- âœ… PII protection out of the box
- âœ… Optimized search algorithms

### vs. Other Memory Libraries
- âœ… **Focused**: Pure memory management, no infrastructure bloat
- âœ… **External Providers**: Easy integration with Supabase, Pinecone, etc.
- âœ… **Lifecycle Management**: Intelligent aging and compression
- âœ… **Simple API**: Get started in minutes, not hours

### vs. Vector Databases Directly
- âœ… **Higher Level**: Memory lifecycle, not just vector storage
- âœ… **Hybrid Search**: Combines keyword + vector search
- âœ… **LLM Integration**: Built-in summarization and compression
- âœ… **Multi-Provider**: Switch between Pinecone, Weaviate, etc. easily

## ğŸ¤ Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.

---

**Get started in 30 seconds:**

```bash
pip install memorizer
```

```python
import memorizer
memory = memorizer.create_memory()
memory.store_memory("user1", "I love coffee")
results = memory.search_memories("user1", "beverages")
print(results.memories[0].content)  # "I love coffee"
```